{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import cess_esp\n",
    "from nltk.tag import UnigramTagger, brill, brill_trainer, CRFTagger\n",
    "from math import sqrt \n",
    "corpus_sentences = cess_esp.tagged_sents()\n",
    "#Transformamos el corpus para reducir categorias como en la practica 2\n",
    "corpus_transformado = []\n",
    "corpus_original = []\n",
    "for sentence in corpus_sentences:\n",
    "    sentence_aux = []\n",
    "    for word, label in sentence:\n",
    "        if(word != \"*0*\"):\n",
    "            if(label.startswith(\"v\") or label.startswith(\"F\")):\n",
    "                sentence_aux.append((word, label[0:3]))\n",
    "            else:\n",
    "                sentence_aux.append((word, label[0:2]))\n",
    "    corpus_transformado.append(sentence_aux)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on module nltk.tag.brill in nltk.tag:\n",
      "\n",
      "NAME\n",
      "    nltk.tag.brill\n",
      "\n",
      "DESCRIPTION\n",
      "    # -*- coding: utf-8 -*-\n",
      "    # Natural Language Toolkit: Transformation-based learning\n",
      "    #\n",
      "    # Copyright (C) 2001-2020 NLTK Project\n",
      "    # Author: Marcus Uneson <marcus.uneson@gmail.com>\n",
      "    #   based on previous (nltk2) version by\n",
      "    #   Christopher Maloof, Edward Loper, Steven Bird\n",
      "    # URL: <http://nltk.org/>\n",
      "    # For license information, see  LICENSE.TXT\n",
      "\n",
      "CLASSES\n",
      "    nltk.tag.api.TaggerI(builtins.object)\n",
      "        BrillTagger\n",
      "    nltk.tbl.feature.Feature(builtins.object)\n",
      "        Pos\n",
      "        Word\n",
      "    \n",
      "    class BrillTagger(nltk.tag.api.TaggerI)\n",
      "     |  BrillTagger(initial_tagger, rules, training_stats=None)\n",
      "     |  \n",
      "     |  Brill's transformational rule-based tagger.  Brill taggers use an\n",
      "     |  initial tagger (such as ``tag.DefaultTagger``) to assign an initial\n",
      "     |  tag sequence to a text; and then apply an ordered list of\n",
      "     |  transformational rules to correct the tags of individual tokens.\n",
      "     |  These transformation rules are specified by the ``TagRule``\n",
      "     |  interface.\n",
      "     |  \n",
      "     |  Brill taggers can be created directly, from an initial tagger and\n",
      "     |  a list of transformational rules; but more often, Brill taggers\n",
      "     |  are created by learning rules from a training corpus, using one\n",
      "     |  of the TaggerTrainers available.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      BrillTagger\n",
      "     |      nltk.tag.api.TaggerI\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, initial_tagger, rules, training_stats=None)\n",
      "     |      :param initial_tagger: The initial tagger\n",
      "     |      :type initial_tagger: TaggerI\n",
      "     |      \n",
      "     |      :param rules: An ordered list of transformation rules that\n",
      "     |          should be used to correct the initial tagging.\n",
      "     |      :type rules: list(TagRule)\n",
      "     |      \n",
      "     |      :param training_stats: A dictionary of statistics collected\n",
      "     |          during training, for possible later use\n",
      "     |      :type training_stats: dict\n",
      "     |  \n",
      "     |  batch_tag_incremental(self, sequences, gold)\n",
      "     |      Tags by applying each rule to the entire corpus (rather than all rules to a\n",
      "     |      single sequence). The point is to collect statistics on the test set for\n",
      "     |      individual rules.\n",
      "     |      \n",
      "     |      NOTE: This is inefficient (does not build any index, so will traverse the entire\n",
      "     |      corpus N times for N rules) -- usually you would not care about statistics for\n",
      "     |      individual rules and thus use batch_tag() instead\n",
      "     |      \n",
      "     |      :param sequences: lists of token sequences (sentences, in some applications) to be tagged\n",
      "     |      :type sequences: list of list of strings\n",
      "     |      :param gold: the gold standard\n",
      "     |      :type gold: list of list of strings\n",
      "     |      :returns: tuple of (tagged_sequences, ordered list of rule scores (one for each rule))\n",
      "     |  \n",
      "     |  encode_json_obj(self)\n",
      "     |  \n",
      "     |  print_template_statistics(self, test_stats=None, printunused=True)\n",
      "     |      Print a list of all templates, ranked according to efficiency.\n",
      "     |      \n",
      "     |      If test_stats is available, the templates are ranked according to their\n",
      "     |      relative contribution (summed for all rules created from a given template,\n",
      "     |      weighted by score) to the performance on the test set. If no test_stats, then\n",
      "     |      statistics collected during training are used instead. There is also\n",
      "     |      an unweighted measure (just counting the rules). This is less informative,\n",
      "     |      though, as many low-score rules will appear towards end of training.\n",
      "     |      \n",
      "     |      :param test_stats: dictionary of statistics collected during testing\n",
      "     |      :type test_stats: dict of str -> any (but usually numbers)\n",
      "     |      :param printunused: if True, print a list of all unused templates\n",
      "     |      :type printunused: bool\n",
      "     |      :return: None\n",
      "     |      :rtype: None\n",
      "     |  \n",
      "     |  rules(self)\n",
      "     |      Return the ordered list of  transformation rules that this tagger has learnt\n",
      "     |      \n",
      "     |      :return: the ordered list of transformation rules that correct the initial tagging\n",
      "     |      :rtype: list of Rules\n",
      "     |  \n",
      "     |  tag(self, tokens)\n",
      "     |      Determine the most appropriate tag sequence for the given\n",
      "     |      token sequence, and return a corresponding list of tagged\n",
      "     |      tokens.  A tagged token is encoded as a tuple ``(token, tag)``.\n",
      "     |      \n",
      "     |      :rtype: list(tuple(str, str))\n",
      "     |  \n",
      "     |  train_stats(self, statistic=None)\n",
      "     |      Return a named statistic collected during training, or a dictionary of all\n",
      "     |      available statistics if no name given\n",
      "     |      \n",
      "     |      :param statistic: name of statistic\n",
      "     |      :type statistic: str\n",
      "     |      :return: some statistic collected during training of this tagger\n",
      "     |      :rtype: any (but usually a number)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  decode_json_obj(obj) from abc.ABCMeta\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  json_tag = 'nltk.tag.BrillTagger'\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.tag.api.TaggerI:\n",
      "     |  \n",
      "     |  evaluate(self, gold)\n",
      "     |      Score the accuracy of the tagger against the gold standard.\n",
      "     |      Strip the tags from the gold standard text, retag it using\n",
      "     |      the tagger, then compute the accuracy score.\n",
      "     |      \n",
      "     |      :type gold: list(list(tuple(str, str)))\n",
      "     |      :param gold: The list of tagged sentences to score the tagger on.\n",
      "     |      :rtype: float\n",
      "     |  \n",
      "     |  tag_sents(self, sentences)\n",
      "     |      Apply ``self.tag()`` to each element of *sentences*.  I.e.:\n",
      "     |      \n",
      "     |          return [self.tag(sent) for sent in sentences]\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.tag.api.TaggerI:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class Pos(nltk.tbl.feature.Feature)\n",
      "     |  Pos(positions, end=None)\n",
      "     |  \n",
      "     |  Feature which examines the tags of nearby tokens.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      Pos\n",
      "     |      nltk.tbl.feature.Feature\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  extract_property(tokens, index)\n",
      "     |      @return: The given token's tag.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  json_tag = 'nltk.tag.brill.Pos'\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.tbl.feature.Feature:\n",
      "     |  \n",
      "     |  __eq__(self, other)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __ge__(self, other)\n",
      "     |      Return self>=value.\n",
      "     |  \n",
      "     |  __gt__(self, other)\n",
      "     |      Return self>value.\n",
      "     |  \n",
      "     |  __init__(self, positions, end=None)\n",
      "     |      Construct a Feature which may apply at C{positions}.\n",
      "     |      \n",
      "     |      #For instance, importing some concrete subclasses (Feature is abstract)\n",
      "     |      >>> from nltk.tag.brill import Word, Pos\n",
      "     |      \n",
      "     |      #Feature Word, applying at one of [-2, -1]\n",
      "     |      >>> Word([-2,-1])\n",
      "     |      Word([-2, -1])\n",
      "     |      \n",
      "     |      #Positions need not be contiguous\n",
      "     |      >>> Word([-2,-1, 1])\n",
      "     |      Word([-2, -1, 1])\n",
      "     |      \n",
      "     |      #Contiguous ranges can alternatively be specified giving the\n",
      "     |      #two endpoints (inclusive)\n",
      "     |      >>> Pos(-3, -1)\n",
      "     |      Pos([-3, -2, -1])\n",
      "     |      \n",
      "     |      #In two-arg form, start <= end is enforced\n",
      "     |      >>> Pos(2, 1)\n",
      "     |      Traceback (most recent call last):\n",
      "     |        File \"<stdin>\", line 1, in <module>\n",
      "     |        File \"nltk/tbl/template.py\", line 306, in __init__\n",
      "     |          raise TypeError\n",
      "     |      ValueError: illegal interval specification: (start=2, end=1)\n",
      "     |      \n",
      "     |      :type positions: list of int\n",
      "     |      :param positions: the positions at which this features should apply\n",
      "     |      :raises ValueError: illegal position specifications\n",
      "     |      \n",
      "     |      An alternative calling convention, for contiguous positions only,\n",
      "     |      is Feature(start, end):\n",
      "     |      \n",
      "     |      :type start: int\n",
      "     |      :param start: start of range where this feature should apply\n",
      "     |      :type end: int\n",
      "     |      :param end: end of range (NOTE: inclusive!) where this feature should apply\n",
      "     |  \n",
      "     |  __le__(self, other)\n",
      "     |      Return self<=value.\n",
      "     |  \n",
      "     |  __lt__(self, other)\n",
      "     |      Return self<value.\n",
      "     |  \n",
      "     |  __ne__(self, other)\n",
      "     |      Return self!=value.\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  encode_json_obj(self)\n",
      "     |  \n",
      "     |  intersects(self, other)\n",
      "     |      Return True if the positions of this Feature intersects with those of other\n",
      "     |      \n",
      "     |      More precisely, return True if this feature refers to the same property as other;\n",
      "     |      and there is some overlap in the positions they look at.\n",
      "     |      \n",
      "     |      #For instance, importing a concrete subclass (Feature is abstract)\n",
      "     |      >>> from nltk.tag.brill import Word, Pos\n",
      "     |      \n",
      "     |      >>> Word([-3,-2,-1]).intersects(Word([-3,-2]))\n",
      "     |      True\n",
      "     |      \n",
      "     |      >>> Word([-3,-2,-1]).intersects(Word([-3,-2, 0]))\n",
      "     |      True\n",
      "     |      \n",
      "     |      >>> Word([-3,-2,-1]).intersects(Word([0]))\n",
      "     |      False\n",
      "     |      \n",
      "     |      #Feature subclasses must agree\n",
      "     |      >>> Word([-3,-2,-1]).intersects(Pos([-3,-2]))\n",
      "     |      False\n",
      "     |      \n",
      "     |      :param other: feature with which to compare\n",
      "     |      :type other: (subclass of) Feature\n",
      "     |      :return: True if feature classes agree and there is some overlap in the positions they look at\n",
      "     |      :rtype: bool\n",
      "     |  \n",
      "     |  issuperset(self, other)\n",
      "     |      Return True if this Feature always returns True when other does\n",
      "     |      \n",
      "     |      More precisely, return True if this feature refers to the same property as other;\n",
      "     |      and this Feature looks at all positions that other does (and possibly\n",
      "     |      other positions in addition).\n",
      "     |      \n",
      "     |      #For instance, importing a concrete subclass (Feature is abstract)\n",
      "     |      >>> from nltk.tag.brill import Word, Pos\n",
      "     |      \n",
      "     |      >>> Word([-3,-2,-1]).issuperset(Word([-3,-2]))\n",
      "     |      True\n",
      "     |      \n",
      "     |      >>> Word([-3,-2,-1]).issuperset(Word([-3,-2, 0]))\n",
      "     |      False\n",
      "     |      \n",
      "     |      #Feature subclasses must agree\n",
      "     |      >>> Word([-3,-2,-1]).issuperset(Pos([-3,-2]))\n",
      "     |      False\n",
      "     |      \n",
      "     |      :param other: feature with which to compare\n",
      "     |      :type other: (subclass of) Feature\n",
      "     |      :return: True if this feature is superset, otherwise False\n",
      "     |      :rtype: bool\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from nltk.tbl.feature.Feature:\n",
      "     |  \n",
      "     |  decode_json_obj(obj) from abc.ABCMeta\n",
      "     |  \n",
      "     |  expand(starts, winlens, excludezero=False) from abc.ABCMeta\n",
      "     |      Return a list of features, one for each start point in starts\n",
      "     |      and for each window length in winlen. If excludezero is True,\n",
      "     |      no Features containing 0 in its positions will be generated\n",
      "     |      (many tbl trainers have a special representation for the\n",
      "     |      target feature at [0])\n",
      "     |      \n",
      "     |      For instance, importing a concrete subclass (Feature is abstract)\n",
      "     |      >>> from nltk.tag.brill import Word\n",
      "     |      \n",
      "     |      First argument gives the possible start positions, second the\n",
      "     |      possible window lengths\n",
      "     |      >>> Word.expand([-3,-2,-1], [1])\n",
      "     |      [Word([-3]), Word([-2]), Word([-1])]\n",
      "     |      \n",
      "     |      >>> Word.expand([-2,-1], [1])\n",
      "     |      [Word([-2]), Word([-1])]\n",
      "     |      \n",
      "     |      >>> Word.expand([-3,-2,-1], [1,2])\n",
      "     |      [Word([-3]), Word([-2]), Word([-1]), Word([-3, -2]), Word([-2, -1])]\n",
      "     |      \n",
      "     |      >>> Word.expand([-2,-1], [1])\n",
      "     |      [Word([-2]), Word([-1])]\n",
      "     |      \n",
      "     |      a third optional argument excludes all Features whose positions contain zero\n",
      "     |      >>> Word.expand([-2,-1,0], [1,2], excludezero=False)\n",
      "     |      [Word([-2]), Word([-1]), Word([0]), Word([-2, -1]), Word([-1, 0])]\n",
      "     |      \n",
      "     |      >>> Word.expand([-2,-1,0], [1,2], excludezero=True)\n",
      "     |      [Word([-2]), Word([-1]), Word([-2, -1])]\n",
      "     |      \n",
      "     |      All window lengths must be positive\n",
      "     |      >>> Word.expand([-2,-1], [0])\n",
      "     |      Traceback (most recent call last):\n",
      "     |        File \"<stdin>\", line 1, in <module>\n",
      "     |        File \"nltk/tag/tbl/template.py\", line 371, in expand\n",
      "     |          :param starts: where to start looking for Feature\n",
      "     |      ValueError: non-positive window length in [0]\n",
      "     |      \n",
      "     |      :param starts: where to start looking for Feature\n",
      "     |      :type starts: list of ints\n",
      "     |      :param winlens: window lengths where to look for Feature\n",
      "     |      :type starts: list of ints\n",
      "     |      :param excludezero: do not output any Feature with 0 in any of its positions.\n",
      "     |      :type excludezero: bool\n",
      "     |      :returns: list of Features\n",
      "     |      :raises ValueError: for non-positive window lengths\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.tbl.feature.Feature:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from nltk.tbl.feature.Feature:\n",
      "     |  \n",
      "     |  PROPERTY_NAME = None\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "    \n",
      "    class Word(nltk.tbl.feature.Feature)\n",
      "     |  Word(positions, end=None)\n",
      "     |  \n",
      "     |  Feature which examines the text (word) of nearby tokens.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      Word\n",
      "     |      nltk.tbl.feature.Feature\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  extract_property(tokens, index)\n",
      "     |      @return: The given token's text.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  json_tag = 'nltk.tag.brill.Word'\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.tbl.feature.Feature:\n",
      "     |  \n",
      "     |  __eq__(self, other)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __ge__(self, other)\n",
      "     |      Return self>=value.\n",
      "     |  \n",
      "     |  __gt__(self, other)\n",
      "     |      Return self>value.\n",
      "     |  \n",
      "     |  __init__(self, positions, end=None)\n",
      "     |      Construct a Feature which may apply at C{positions}.\n",
      "     |      \n",
      "     |      #For instance, importing some concrete subclasses (Feature is abstract)\n",
      "     |      >>> from nltk.tag.brill import Word, Pos\n",
      "     |      \n",
      "     |      #Feature Word, applying at one of [-2, -1]\n",
      "     |      >>> Word([-2,-1])\n",
      "     |      Word([-2, -1])\n",
      "     |      \n",
      "     |      #Positions need not be contiguous\n",
      "     |      >>> Word([-2,-1, 1])\n",
      "     |      Word([-2, -1, 1])\n",
      "     |      \n",
      "     |      #Contiguous ranges can alternatively be specified giving the\n",
      "     |      #two endpoints (inclusive)\n",
      "     |      >>> Pos(-3, -1)\n",
      "     |      Pos([-3, -2, -1])\n",
      "     |      \n",
      "     |      #In two-arg form, start <= end is enforced\n",
      "     |      >>> Pos(2, 1)\n",
      "     |      Traceback (most recent call last):\n",
      "     |        File \"<stdin>\", line 1, in <module>\n",
      "     |        File \"nltk/tbl/template.py\", line 306, in __init__\n",
      "     |          raise TypeError\n",
      "     |      ValueError: illegal interval specification: (start=2, end=1)\n",
      "     |      \n",
      "     |      :type positions: list of int\n",
      "     |      :param positions: the positions at which this features should apply\n",
      "     |      :raises ValueError: illegal position specifications\n",
      "     |      \n",
      "     |      An alternative calling convention, for contiguous positions only,\n",
      "     |      is Feature(start, end):\n",
      "     |      \n",
      "     |      :type start: int\n",
      "     |      :param start: start of range where this feature should apply\n",
      "     |      :type end: int\n",
      "     |      :param end: end of range (NOTE: inclusive!) where this feature should apply\n",
      "     |  \n",
      "     |  __le__(self, other)\n",
      "     |      Return self<=value.\n",
      "     |  \n",
      "     |  __lt__(self, other)\n",
      "     |      Return self<value.\n",
      "     |  \n",
      "     |  __ne__(self, other)\n",
      "     |      Return self!=value.\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  encode_json_obj(self)\n",
      "     |  \n",
      "     |  intersects(self, other)\n",
      "     |      Return True if the positions of this Feature intersects with those of other\n",
      "     |      \n",
      "     |      More precisely, return True if this feature refers to the same property as other;\n",
      "     |      and there is some overlap in the positions they look at.\n",
      "     |      \n",
      "     |      #For instance, importing a concrete subclass (Feature is abstract)\n",
      "     |      >>> from nltk.tag.brill import Word, Pos\n",
      "     |      \n",
      "     |      >>> Word([-3,-2,-1]).intersects(Word([-3,-2]))\n",
      "     |      True\n",
      "     |      \n",
      "     |      >>> Word([-3,-2,-1]).intersects(Word([-3,-2, 0]))\n",
      "     |      True\n",
      "     |      \n",
      "     |      >>> Word([-3,-2,-1]).intersects(Word([0]))\n",
      "     |      False\n",
      "     |      \n",
      "     |      #Feature subclasses must agree\n",
      "     |      >>> Word([-3,-2,-1]).intersects(Pos([-3,-2]))\n",
      "     |      False\n",
      "     |      \n",
      "     |      :param other: feature with which to compare\n",
      "     |      :type other: (subclass of) Feature\n",
      "     |      :return: True if feature classes agree and there is some overlap in the positions they look at\n",
      "     |      :rtype: bool\n",
      "     |  \n",
      "     |  issuperset(self, other)\n",
      "     |      Return True if this Feature always returns True when other does\n",
      "     |      \n",
      "     |      More precisely, return True if this feature refers to the same property as other;\n",
      "     |      and this Feature looks at all positions that other does (and possibly\n",
      "     |      other positions in addition).\n",
      "     |      \n",
      "     |      #For instance, importing a concrete subclass (Feature is abstract)\n",
      "     |      >>> from nltk.tag.brill import Word, Pos\n",
      "     |      \n",
      "     |      >>> Word([-3,-2,-1]).issuperset(Word([-3,-2]))\n",
      "     |      True\n",
      "     |      \n",
      "     |      >>> Word([-3,-2,-1]).issuperset(Word([-3,-2, 0]))\n",
      "     |      False\n",
      "     |      \n",
      "     |      #Feature subclasses must agree\n",
      "     |      >>> Word([-3,-2,-1]).issuperset(Pos([-3,-2]))\n",
      "     |      False\n",
      "     |      \n",
      "     |      :param other: feature with which to compare\n",
      "     |      :type other: (subclass of) Feature\n",
      "     |      :return: True if this feature is superset, otherwise False\n",
      "     |      :rtype: bool\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from nltk.tbl.feature.Feature:\n",
      "     |  \n",
      "     |  decode_json_obj(obj) from abc.ABCMeta\n",
      "     |  \n",
      "     |  expand(starts, winlens, excludezero=False) from abc.ABCMeta\n",
      "     |      Return a list of features, one for each start point in starts\n",
      "     |      and for each window length in winlen. If excludezero is True,\n",
      "     |      no Features containing 0 in its positions will be generated\n",
      "     |      (many tbl trainers have a special representation for the\n",
      "     |      target feature at [0])\n",
      "     |      \n",
      "     |      For instance, importing a concrete subclass (Feature is abstract)\n",
      "     |      >>> from nltk.tag.brill import Word\n",
      "     |      \n",
      "     |      First argument gives the possible start positions, second the\n",
      "     |      possible window lengths\n",
      "     |      >>> Word.expand([-3,-2,-1], [1])\n",
      "     |      [Word([-3]), Word([-2]), Word([-1])]\n",
      "     |      \n",
      "     |      >>> Word.expand([-2,-1], [1])\n",
      "     |      [Word([-2]), Word([-1])]\n",
      "     |      \n",
      "     |      >>> Word.expand([-3,-2,-1], [1,2])\n",
      "     |      [Word([-3]), Word([-2]), Word([-1]), Word([-3, -2]), Word([-2, -1])]\n",
      "     |      \n",
      "     |      >>> Word.expand([-2,-1], [1])\n",
      "     |      [Word([-2]), Word([-1])]\n",
      "     |      \n",
      "     |      a third optional argument excludes all Features whose positions contain zero\n",
      "     |      >>> Word.expand([-2,-1,0], [1,2], excludezero=False)\n",
      "     |      [Word([-2]), Word([-1]), Word([0]), Word([-2, -1]), Word([-1, 0])]\n",
      "     |      \n",
      "     |      >>> Word.expand([-2,-1,0], [1,2], excludezero=True)\n",
      "     |      [Word([-2]), Word([-1]), Word([-2, -1])]\n",
      "     |      \n",
      "     |      All window lengths must be positive\n",
      "     |      >>> Word.expand([-2,-1], [0])\n",
      "     |      Traceback (most recent call last):\n",
      "     |        File \"<stdin>\", line 1, in <module>\n",
      "     |        File \"nltk/tag/tbl/template.py\", line 371, in expand\n",
      "     |          :param starts: where to start looking for Feature\n",
      "     |      ValueError: non-positive window length in [0]\n",
      "     |      \n",
      "     |      :param starts: where to start looking for Feature\n",
      "     |      :type starts: list of ints\n",
      "     |      :param winlens: window lengths where to look for Feature\n",
      "     |      :type starts: list of ints\n",
      "     |      :param excludezero: do not output any Feature with 0 in any of its positions.\n",
      "     |      :type excludezero: bool\n",
      "     |      :returns: list of Features\n",
      "     |      :raises ValueError: for non-positive window lengths\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.tbl.feature.Feature:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from nltk.tbl.feature.Feature:\n",
      "     |  \n",
      "     |  PROPERTY_NAME = None\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "\n",
      "FUNCTIONS\n",
      "    brill24()\n",
      "        Return 24 templates of the seminal TBL paper, Brill (1995)\n",
      "    \n",
      "    describe_template_sets()\n",
      "        Print the available template sets in this demo, with a short description\"\n",
      "    \n",
      "    fntbl37()\n",
      "        Return 37 templates taken from the postagging task of the\n",
      "        fntbl distribution http://www.cs.jhu.edu/~rflorian/fntbl/\n",
      "        (37 is after excluding a handful which do not condition on Pos[0];\n",
      "        fntbl can do that but the current nltk implementation cannot.)\n",
      "    \n",
      "    nltkdemo18()\n",
      "        Return 18 templates, from the original nltk demo, in multi-feature syntax\n",
      "    \n",
      "    nltkdemo18plus()\n",
      "        Return 18 templates, from the original nltk demo, and additionally a few\n",
      "        multi-feature ones (the motivation is easy comparison with nltkdemo18)\n",
      "\n",
      "FILE\n",
      "    d:\\anaconda\\lib\\site-packages\\nltk\\tag\\brill.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(nltk.tag.brill)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on module nltk.tag.brill_trainer in nltk.tag:\n",
      "\n",
      "NAME\n",
      "    nltk.tag.brill_trainer\n",
      "\n",
      "DESCRIPTION\n",
      "    # -*- coding: utf-8 -*-\n",
      "    # Natural Language Toolkit: Transformation-based learning\n",
      "    #\n",
      "    # Copyright (C) 2001-2013 NLTK Project\n",
      "    # Author: Marcus Uneson <marcus.uneson@gmail.com>\n",
      "    #   based on previous (nltk2) version by\n",
      "    #   Christopher Maloof, Edward Loper, Steven Bird\n",
      "    # URL: <http://nltk.org/>\n",
      "    # For license information, see  LICENSE.TXT\n",
      "\n",
      "CLASSES\n",
      "    builtins.object\n",
      "        BrillTaggerTrainer\n",
      "    \n",
      "    class BrillTaggerTrainer(builtins.object)\n",
      "     |  BrillTaggerTrainer(initial_tagger, templates, trace=0, deterministic=None, ruleformat='str')\n",
      "     |  \n",
      "     |  A trainer for tbl taggers.\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, initial_tagger, templates, trace=0, deterministic=None, ruleformat='str')\n",
      "     |      Construct a Brill tagger from a baseline tagger and a\n",
      "     |      set of templates\n",
      "     |      \n",
      "     |      :param initial_tagger: the baseline tagger\n",
      "     |      :type initial_tagger: Tagger\n",
      "     |      :param templates: templates to be used in training\n",
      "     |      :type templates: list of Templates\n",
      "     |      :param trace: verbosity level\n",
      "     |      :type trace: int\n",
      "     |      :param deterministic: if True, adjudicate ties deterministically\n",
      "     |      :type deterministic: bool\n",
      "     |      :param ruleformat: format of reported Rules\n",
      "     |      :type ruleformat: str\n",
      "     |      :return: An untrained BrillTagger\n",
      "     |      :rtype: BrillTagger\n",
      "     |  \n",
      "     |  train(self, train_sents, max_rules=200, min_score=2, min_acc=None)\n",
      "     |      Trains the Brill tagger on the corpus *train_sents*,\n",
      "     |      producing at most *max_rules* transformations, each of which\n",
      "     |      reduces the net number of errors in the corpus by at least\n",
      "     |      *min_score*, and each of which has accuracy not lower than\n",
      "     |      *min_acc*.\n",
      "     |      \n",
      "     |      #imports\n",
      "     |      >>> from nltk.tbl.template import Template\n",
      "     |      >>> from nltk.tag.brill import Pos, Word\n",
      "     |      >>> from nltk.tag import untag, RegexpTagger, BrillTaggerTrainer\n",
      "     |      \n",
      "     |      #some data\n",
      "     |      >>> from nltk.corpus import treebank\n",
      "     |      >>> training_data = treebank.tagged_sents()[:100]\n",
      "     |      >>> baseline_data = treebank.tagged_sents()[100:200]\n",
      "     |      >>> gold_data = treebank.tagged_sents()[200:300]\n",
      "     |      >>> testing_data = [untag(s) for s in gold_data]\n",
      "     |      \n",
      "     |      >>> backoff = RegexpTagger([\n",
      "     |      ... (r'^-?[0-9]+(.[0-9]+)?$', 'CD'),   # cardinal numbers\n",
      "     |      ... (r'(The|the|A|a|An|an)$', 'AT'),   # articles\n",
      "     |      ... (r'.*able$', 'JJ'),                # adjectives\n",
      "     |      ... (r'.*ness$', 'NN'),                # nouns formed from adjectives\n",
      "     |      ... (r'.*ly$', 'RB'),                  # adverbs\n",
      "     |      ... (r'.*s$', 'NNS'),                  # plural nouns\n",
      "     |      ... (r'.*ing$', 'VBG'),                # gerunds\n",
      "     |      ... (r'.*ed$', 'VBD'),                 # past tense verbs\n",
      "     |      ... (r'.*', 'NN')                      # nouns (default)\n",
      "     |      ... ])\n",
      "     |      \n",
      "     |      >>> baseline = backoff #see NOTE1\n",
      "     |      \n",
      "     |      >>> baseline.evaluate(gold_data) #doctest: +ELLIPSIS\n",
      "     |      0.2450142...\n",
      "     |      \n",
      "     |      #templates\n",
      "     |      >>> Template._cleartemplates() #clear any templates created in earlier tests\n",
      "     |      >>> templates = [Template(Pos([-1])), Template(Pos([-1]), Word([0]))]\n",
      "     |      \n",
      "     |      #construct a BrillTaggerTrainer\n",
      "     |      >>> tt = BrillTaggerTrainer(baseline, templates, trace=3)\n",
      "     |      \n",
      "     |      >>> tagger1 = tt.train(training_data, max_rules=10)\n",
      "     |      TBL train (fast) (seqs: 100; tokens: 2417; tpls: 2; min score: 2; min acc: None)\n",
      "     |      Finding initial useful rules...\n",
      "     |          Found 845 useful rules.\n",
      "     |      <BLANKLINE>\n",
      "     |                 B      |\n",
      "     |         S   F   r   O  |        Score = Fixed - Broken\n",
      "     |         c   i   o   t  |  R     Fixed = num tags changed incorrect -> correct\n",
      "     |         o   x   k   h  |  u     Broken = num tags changed correct -> incorrect\n",
      "     |         r   e   e   e  |  l     Other = num tags changed incorrect -> incorrect\n",
      "     |         e   d   n   r  |  e\n",
      "     |      ------------------+-------------------------------------------------------\n",
      "     |       132 132   0   0  | AT->DT if Pos:NN@[-1]\n",
      "     |        85  85   0   0  | NN->, if Pos:NN@[-1] & Word:,@[0]\n",
      "     |        69  69   0   0  | NN->. if Pos:NN@[-1] & Word:.@[0]\n",
      "     |        51  51   0   0  | NN->IN if Pos:NN@[-1] & Word:of@[0]\n",
      "     |        47  63  16 161  | NN->IN if Pos:NNS@[-1]\n",
      "     |        33  33   0   0  | NN->TO if Pos:NN@[-1] & Word:to@[0]\n",
      "     |        26  26   0   0  | IN->. if Pos:NNS@[-1] & Word:.@[0]\n",
      "     |        24  24   0   0  | IN->, if Pos:NNS@[-1] & Word:,@[0]\n",
      "     |        22  27   5  24  | NN->-NONE- if Pos:VBD@[-1]\n",
      "     |        17  17   0   0  | NN->CC if Pos:NN@[-1] & Word:and@[0]\n",
      "     |      \n",
      "     |      >>> tagger1.rules()[1:3]\n",
      "     |      (Rule('001', 'NN', ',', [(Pos([-1]),'NN'), (Word([0]),',')]), Rule('001', 'NN', '.', [(Pos([-1]),'NN'), (Word([0]),'.')]))\n",
      "     |      \n",
      "     |      >>> train_stats = tagger1.train_stats()\n",
      "     |      >>> [train_stats[stat] for stat in ['initialerrors', 'finalerrors', 'rulescores']]\n",
      "     |      [1775, 1269, [132, 85, 69, 51, 47, 33, 26, 24, 22, 17]]\n",
      "     |      \n",
      "     |      >>> tagger1.print_template_statistics(printunused=False)\n",
      "     |      TEMPLATE STATISTICS (TRAIN)  2 templates, 10 rules)\n",
      "     |      TRAIN (   2417 tokens) initial  1775 0.2656 final:  1269 0.4750\n",
      "     |      #ID | Score (train) |  #Rules     | Template\n",
      "     |      --------------------------------------------\n",
      "     |      001 |   305   0.603 |   7   0.700 | Template(Pos([-1]),Word([0]))\n",
      "     |      000 |   201   0.397 |   3   0.300 | Template(Pos([-1]))\n",
      "     |      <BLANKLINE>\n",
      "     |      <BLANKLINE>\n",
      "     |      \n",
      "     |      >>> tagger1.evaluate(gold_data) # doctest: +ELLIPSIS\n",
      "     |      0.43996...\n",
      "     |      \n",
      "     |      >>> tagged, test_stats = tagger1.batch_tag_incremental(testing_data, gold_data)\n",
      "     |      \n",
      "     |      >>> tagged[33][12:] == [('foreign', 'IN'), ('debt', 'NN'), ('of', 'IN'), ('$', 'NN'), ('64', 'CD'),\n",
      "     |      ... ('billion', 'NN'), ('*U*', 'NN'), ('--', 'NN'), ('the', 'DT'), ('third-highest', 'NN'), ('in', 'NN'),\n",
      "     |      ... ('the', 'DT'), ('developing', 'VBG'), ('world', 'NN'), ('.', '.')]\n",
      "     |      True\n",
      "     |      \n",
      "     |      >>> [test_stats[stat] for stat in ['initialerrors', 'finalerrors', 'rulescores']]\n",
      "     |      [1855, 1376, [100, 85, 67, 58, 27, 36, 27, 16, 31, 32]]\n",
      "     |      \n",
      "     |      # a high-accuracy tagger\n",
      "     |      >>> tagger2 = tt.train(training_data, max_rules=10, min_acc=0.99)\n",
      "     |      TBL train (fast) (seqs: 100; tokens: 2417; tpls: 2; min score: 2; min acc: 0.99)\n",
      "     |      Finding initial useful rules...\n",
      "     |          Found 845 useful rules.\n",
      "     |      <BLANKLINE>\n",
      "     |                 B      |\n",
      "     |         S   F   r   O  |        Score = Fixed - Broken\n",
      "     |         c   i   o   t  |  R     Fixed = num tags changed incorrect -> correct\n",
      "     |         o   x   k   h  |  u     Broken = num tags changed correct -> incorrect\n",
      "     |         r   e   e   e  |  l     Other = num tags changed incorrect -> incorrect\n",
      "     |         e   d   n   r  |  e\n",
      "     |      ------------------+-------------------------------------------------------\n",
      "     |       132 132   0   0  | AT->DT if Pos:NN@[-1]\n",
      "     |        85  85   0   0  | NN->, if Pos:NN@[-1] & Word:,@[0]\n",
      "     |        69  69   0   0  | NN->. if Pos:NN@[-1] & Word:.@[0]\n",
      "     |        51  51   0   0  | NN->IN if Pos:NN@[-1] & Word:of@[0]\n",
      "     |        36  36   0   0  | NN->TO if Pos:NN@[-1] & Word:to@[0]\n",
      "     |        26  26   0   0  | NN->. if Pos:NNS@[-1] & Word:.@[0]\n",
      "     |        24  24   0   0  | NN->, if Pos:NNS@[-1] & Word:,@[0]\n",
      "     |        19  19   0   6  | NN->VB if Pos:TO@[-1]\n",
      "     |        18  18   0   0  | CD->-NONE- if Pos:NN@[-1] & Word:0@[0]\n",
      "     |        18  18   0   0  | NN->CC if Pos:NN@[-1] & Word:and@[0]\n",
      "     |      \n",
      "     |      >>> tagger2.evaluate(gold_data)  # doctest: +ELLIPSIS\n",
      "     |      0.44159544...\n",
      "     |      >>> tagger2.rules()[2:4]\n",
      "     |      (Rule('001', 'NN', '.', [(Pos([-1]),'NN'), (Word([0]),'.')]), Rule('001', 'NN', 'IN', [(Pos([-1]),'NN'), (Word([0]),'of')]))\n",
      "     |      \n",
      "     |      # NOTE1: (!!FIXME) A far better baseline uses nltk.tag.UnigramTagger,\n",
      "     |      # with a RegexpTagger only as backoff. For instance,\n",
      "     |      # >>> baseline = UnigramTagger(baseline_data, backoff=backoff)\n",
      "     |      # However, as of Nov 2013, nltk.tag.UnigramTagger does not yield consistent results\n",
      "     |      # between python versions. The simplistic backoff above is a workaround to make doctests\n",
      "     |      # get consistent input.\n",
      "     |      \n",
      "     |      :param train_sents: training data\n",
      "     |      :type train_sents: list(list(tuple))\n",
      "     |      :param max_rules: output at most max_rules rules\n",
      "     |      :type max_rules: int\n",
      "     |      :param min_score: stop training when no rules better than min_score can be found\n",
      "     |      :type min_score: int\n",
      "     |      :param min_acc: discard any rule with lower accuracy than min_acc\n",
      "     |      :type min_acc: float or None\n",
      "     |      :return: the learned tagger\n",
      "     |      :rtype: BrillTagger\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "\n",
      "FILE\n",
      "    d:\\anaconda\\lib\\site-packages\\nltk\\tag\\brill_trainer.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(nltk.tag.brill_trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creamos diez particiones del corpus tranformado despúes de barajarlo para realizar Cross-Validation\n",
    "from random import shuffle \n",
    "corpus_barajado = corpus_transformado\n",
    "shuffle(corpus_barajado)\n",
    "longitud_particion = len(corpus_barajado)//10\n",
    "particionTest = corpus_barajado[0:longitud_particion]\n",
    "particionTrain = corpus_barajado[longitud_particion:]\n",
    "palabrasTest = 0\n",
    "for sentence in particionTest:\n",
    "    for word in sentence:\n",
    "        palabrasTest += 1   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9026496459987127 0.004255150251665331\n"
     ]
    }
   ],
   "source": [
    "unigram = UnigramTagger(particionTrain)\n",
    "brill.Template._cleartemplates()\n",
    "templates = brill.fntbl37()\n",
    "brillTrainer = nltk.tag.brill_trainer.BrillTaggerTrainer(initial_tagger=unigram, templates = templates)\n",
    "tagger1 = brillTrainer.train(particionTrain,max_rules = 200)\n",
    "precision = tagger1.evaluate(particionTest)\n",
    "s = sqrt(precision*(1-precision)/palabrasTest) \n",
    "intervalo = 1.96*s \n",
    "print(precision,intervalo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TBL train (fast) (seqs: 5427; tokens: 170159; tpls: 24; min score: 2; min acc: None)\n",
      "Finding initial useful rules...\n",
      "    Found 55489 useful rules.\n",
      "Selecting rules...\n",
      "0.9023814632053208 0.004260374276316841\n"
     ]
    }
   ],
   "source": [
    "unigram = UnigramTagger(particionTrain)\n",
    "brill.Template._cleartemplates()\n",
    "templates = brill.brill24()\n",
    "brillTrainer = nltk.tag.brill_trainer.BrillTaggerTrainer(initial_tagger=unigram, templates = templates, trace=1)\n",
    "tagger1 = brillTrainer.train(particionTrain, max_rules = 200)\n",
    "precision = tagger1.evaluate(particionTest)\n",
    "s = sqrt(precision*(1-precision)/palabrasTest) \n",
    "intervalo = 1.96*s \n",
    "print(precision,intervalo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TBL train (fast) (seqs: 5427; tokens: 170159; tpls: 23; min score: 2; min acc: None)\n",
      "Finding initial useful rules...\n",
      "    Found 70517 useful rules.\n",
      "Selecting rules...\n",
      "0.9018450976185368 0.004270792745748961\n"
     ]
    }
   ],
   "source": [
    "unigram = UnigramTagger(particionTrain)\n",
    "brill.Template._cleartemplates()\n",
    "templates = brill.nltkdemo18plus()\n",
    "brillTrainer = nltk.tag.brill_trainer.BrillTaggerTrainer(initial_tagger=unigram, templates = templates, trace=1)\n",
    "tagger1 = brillTrainer.train(particionTrain, max_rules = 200)\n",
    "precision = tagger1.evaluate(particionTest)\n",
    "s = sqrt(precision*(1-precision)/palabrasTest) \n",
    "intervalo = 1.96*s \n",
    "print(precision,intervalo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TBL train (fast) (seqs: 5427; tokens: 170159; tpls: 37; min score: 2; min acc: None)\n",
      "Finding initial useful rules...\n",
      "    Found 131188 useful rules.\n",
      "Selecting rules...\n",
      "0.9342415790602875 0.0035578841947357734\n"
     ]
    }
   ],
   "source": [
    "from nltk import hmm\n",
    "tagger_hmm = hmm.HiddenMarkovModelTagger.train(particionTrain)\n",
    "brill.Template._cleartemplates()\n",
    "templates = brill.fntbl37()\n",
    "brillTrainer = nltk.tag.brill_trainer.BrillTaggerTrainer(initial_tagger=tagger_hmm, templates = templates, trace=1)\n",
    "tagger1 = brillTrainer.train(particionTrain, max_rules = 200)\n",
    "precision = tagger1.evaluate(particionTest)\n",
    "s = sqrt(precision*(1-precision)/palabrasTest) \n",
    "intervalo = 1.96*s \n",
    "print(precision,intervalo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TBL train (fast) (seqs: 5427; tokens: 170159; tpls: 24; min score: 2; min acc: None)\n",
      "Finding initial useful rules...\n",
      "    Found 76888 useful rules.\n",
      "Selecting rules...\n",
      "0.9342952156189659 0.0035565349748723787\n"
     ]
    }
   ],
   "source": [
    "tagger_hmm = hmm.HiddenMarkovModelTagger.train(particionTrain)\n",
    "brill.Template._cleartemplates()\n",
    "templates = brill.brill24()\n",
    "brillTrainer = nltk.tag.brill_trainer.BrillTaggerTrainer(initial_tagger=tagger_hmm, templates = templates, trace=1)\n",
    "tagger1 = brillTrainer.train(particionTrain, max_rules = 200)\n",
    "precision = tagger1.evaluate(particionTest)\n",
    "s = sqrt(precision*(1-precision)/palabrasTest) \n",
    "intervalo = 1.96*s \n",
    "print(precision,intervalo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TBL train (fast) (seqs: 5427; tokens: 170159; tpls: 23; min score: 2; min acc: None)\n",
      "Finding initial useful rules...\n",
      "    Found 82776 useful rules.\n",
      "Selecting rules...\n",
      "0.9338124865908604 0.0035686536099966836\n"
     ]
    }
   ],
   "source": [
    "tagger_hmm = hmm.HiddenMarkovModelTagger.train(particionTrain)\n",
    "brill.Template._cleartemplates()\n",
    "templates = brill.nltkdemo18plus()\n",
    "brillTrainer = nltk.tag.brill_trainer.BrillTaggerTrainer(initial_tagger=tagger_hmm, templates = templates, trace=1)\n",
    "tagger1 = brillTrainer.train(particionTrain, max_rules = 200)\n",
    "precision = tagger1.evaluate(particionTest)\n",
    "s = sqrt(precision*(1-precision)/palabrasTest) \n",
    "intervalo = 1.96*s \n",
    "print(precision,intervalo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.970553529285561 0.0024266821517585366\n"
     ]
    }
   ],
   "source": [
    "from nltk.tag.perceptron import PerceptronTagger\n",
    "pt = PerceptronTagger(load=False)\n",
    "pt.train(particionTrain)\n",
    "precision = pt.evaluate(particionTest)\n",
    "s = sqrt(precision*(1-precision)/palabrasTest) \n",
    "intervalo = 1.96*s \n",
    "print(precision,intervalo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
